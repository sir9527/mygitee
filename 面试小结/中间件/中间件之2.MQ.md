

[TOC]



![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210613144409.png)





```markdown
参考博客：https://mp.weixin.qq.com/s/diz6okteXvH-y4QQvIl2Xw
```





## 1.MQ基础

### 1.1 MQ的作用

- 异步处理（比异步线程更快，不需要等待结果）
  场景说明：用户注册后，需要发注册邮件和注册短信

- 解耦：订单系统发消息，库存系统接收消息之后进行处理

  场景说明：用户下单后,订单系统需要通知库存系统

- 流量控制（流量削峰）：根据秒杀系统能力处理消息
  场景说明：秒杀活动，流量过大，消息队列控制流量人数



### 1.2 MQ引入后的问题

#### 1.2.1 重复消息问题

```java
消息重复的原因有两个
- 1.生产时消息重复
- 2.消费时消息重复
    
解决：让每个消息携带一个全局的唯一ID，即可保证消息的幂等性。具体消费过程为：
1.消费者获取到消息后先根据id去查询redis/db是否存在该消息。
2.如果不存在，则正常消费，消费完毕后写入redis/db ；如果存在，则证明消息被消费过，直接丢弃。
```



例：比如人家开了一个月会员，你消息重复给人家开了两个月会员

解决：消费者在做业务处理时，要做幂等设计。通过唯一索引查询其处理状态做幂等。



#### 1.2.2 数据一致性问题

消费消息失败可以写入重试表中，通过定时任务读取重试表进行重新消费。



![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210613093603.png)



#### 1.2.3 消息丢失问题

```markdown
一条消息从生产到消费经历了三个阶段，分别是生产者，MQ和消费者，对于RabbitMQ来说，消息的传递还涉及到交换机。因此RabbitMQ出现消息丢失的情况有四个，分别是
- 1.消息生产者没有成功将消息发送到MQ导致消息丢失    ACK确认机制
    spring.rabbitmq.publisher-confirm-type=correlated
- 2.交换机未路由到消息队列导致消息丢失            
    // 消息从交换机未能匹配到队列时将此条消息返回给生产者
    spring.rabbitmq.publisher-returns=true
- 3.消息在MQ中时，MQ发生宕机导致消息丢失          持久化队列
- 4.消费者消费消息时出现异常导致消息丢失           ACK确认机制
    spring.rabbitmq.listener.simple.acknowledge-mode=manual
```



通用解决方案：我们可以增加一张`消息发送表`，当生产者发完消息之后，会往该表中写入一条数据，状态status标记为待确认。如果消费者读取消息之后，调用生产者的api更新该消息的status为已确认。有个job，每隔一段时间检查一次消息发送表，如果5分钟（这个时间可以根据实际情况来定）后还有状态是待确认的消息，则认为该消息已经丢失了，重新发条消息。 

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210613093633.png)





#### 1.2.4 消息顺序问题

例：电商中下单、支付、完成，需要保证顺序

解决：

- kafka解决：
  
- kafka写入partion时指定一个key，列如订单id，确保进去同一个`partition`，单个partition的写入是有顺序的；消费者也只能有一个。
  
  - 通过给唯一key值将同一业务的数据写到同一个分区中，保证写入有序，具体代码： kafkaTemplate.send(event.getTopic(),event.getUserId(),JSONObject.toJSONString(event)); 

- RocketMQ解决

  - 可以严格的保证消息有序，可以分为 分区有序 或者 全局有序。

  - 当发送和消费参与的queue只有一个，则是全局有序(一般没有必要)；

  - 如果多个queue参与，则为分区有序，即相对每个queue，消息都是有序的(同一个订单id放入一个队列)。

    

#### 1.2.5 消息堆积

例：人家开了会员，你消费者消费太慢，让人家登录好几天才变成会员。



如果不需要保证顺序，可以读取消息之后用多线程处理业务逻辑。 

如果需要保证顺序，可以读取消息之后，将消息按照一定的规则分发到多个队列中，然后在队列中用单线程处理。 





#### 1.2.6 死信队列如何处理

```markdown

当一条消息在队列中出现以下三种情况的时候，该消息就会变成一条死信。
- 消息被拒绝(basic.reject / basic.nack)，并且requeue = false
- 消息TTL过期
- 队列达到最大长度


当消息在一个队列中变成一个死信之后，如果配置了死信队列，它将被重新publish到死信交换机，死信交换机将死信投递到一个队列上，这个队列就是死信队列。


一条消息成为死信后，一般会通过死信队列进行存库，然后定时将库中的死信进行重新投递到消息队列上

```





![死信队列](./image/死信队列.png)





## 2.MQ之Kafka

### 2.1 Kafka基础知识

Kafka 其实是一个轻量级的 MQ ， 在延迟队列、重试机制等高级特性上并未做支持 



为了提高一个队列(topic)的吞吐量，Kafka会把topic进行分区(Partition)

一个topic会分为多个partition，实际上partition会分布在不同的broker中，往topic里边丢数据，实际上这些数据会分到不同的partition上，这些partition存在不同的broker上



partition 中的每条 Message 包含三个属性：`offset`，`MessageSize`，`data`

-  offset 表 示 Message 在这个 partition 中的**偏移量**。offset 不是该 Message 在 partition 数据文件中的实际存储位置，而是逻辑上一个值，它唯一确定了 partition 中的一条 Message，可以认为 offset 是 partition 中 Message 的 **id** 

-  MessageSize 表示消息内容 data 的**大小** 

-  data 为 Message 的**具体内容** 



### 2.2 Kafka架构图及其组件

- *broker*：Kafka 服务器，负责消息**存储**和**转发**
- *topic*：消息类别，Kafka 按照 topic 来**分类消息**

- *partition*：topic 的**分区**，一个 topic 可以包含多个 partition，topic 消息保存在各个 partition 上

- *offset*：消息在日志中的位置，可以理解是消息在 partition 上的**偏移量**，也是代表该消息的唯一序号

- *Producer*：消息生产者
- *Consumer*：消息消费者
- *Consumer Group*：消费者**分组**，每个 Consumer 必须属于一个 group
- *Zookeeper*：保存着集群 broker、topic、partition 等 `meta` 数据；另外，还负责 broker 故障发现，partition leader 选举，负载均衡等功能



![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210613100956.png)



注：生产者往一个topic里边丢数据，实际上数据会再partition中，partition会分布在不用的broker上。橙色是主分区，白色是备份分区。备份不做读写，如果某个Broker挂了，那就会选举出其他Broker的partition来作为主分区，这就实现了高可用。

注：消费者会从主分区中消费。图中partition0、partition1、partition2是一个topic。



### 2.3 kafka消息类型
#### 2.3.1 点对点模式（1对1）
消息生产者生产消息发送到Queue中，然后消息消费者从Queue中取出并且消费消息。 
消息被消费以后，queue 中不再有存储，所以消息消费者不可能消费到已经被消费的消息。 
Queue 支持存在多个消费者，但是对一个消息而言，只会有一个消费者可以消费。

注：消费者主动拉取数据，消息收到后消息清除

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210607132332.png)


#### 2.3.2 发布/订阅模式（1对多）
消息生产者（发布）将消息发布到 topic 中，同时有多个消息消费者（订阅）消费该消息。
和点对点方式不同，发布到 topic 的消息会被所有订阅者消费。

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210607132358.png)



### 2.4 Kafka的消息存储（参考RocketMQ）



### 2.5 Kafka的刷盘机制：只支持 **异步刷盘**



### 2.6 Kafka的高可用：partition在多个实例中有备份



## 3.RocketMQ

### 3.1 RocketMQ基础知识

### 3.2 RocketMQ架构图及其组件

* Producer：消息的发送者

* Consumer：消息接收者

* Broker：RocketMQ服务器

  Broker部署相对复杂，Broker分为Master与Slave，一个Master可以对应多个Slave，但是一个Slave只能对应一个Master，Master与Slave的对应关系通过指定相同的BrokerName，不同的BrokerId来定义，BrokerId为0表示Master，非0表示Slave。Master也可以部署多个。每个Broker与NameServer集群中的所有节点建立长连接，定时注册Topic信息到所有NameServer。

* NameServer：管理Broker；举例：各个邮局的管理机构

* Topic：区分消息的种类；一个发送者可以发送消息给一个或者多个Topic；一个消息的接收者可以订阅一个或者多个Topic消息

*  消息属性：生产者发送的时候可以为消息自定义一些业务相关的属性，比如 Message Key 和 Tag 等 

* offset



![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210606151918.png)



### 3.3 RocketMQ消息类型

#### 3.3.1 消息发送

- 发送同步消息：可靠性同步地发送方式使用的比较广泛，比如：重要的消息通知，短信通知。
- 发送异步消息：对响应时间敏感的业务场景，即发送端不能容忍长时间地等待Broker的响应。
- 单向发送消息：不特别关心发送结果的场景，例如日志发送。

#### 3.3.2 消息消费

- 负载均衡模式：消费者采用负载均衡方式消费消息，多个消费者共同消费队列消息，每个消费者处理的消息不同
- 广播模式：消费者采用广播的方式消费消息，每个消费者消费的消息都是相同的

#### 3.3.3 其他消息类型：顺序消息、延时消息、批量消息、过滤消息、事务消息



### 3.4 RocketMQ消息存储和发送

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210607102839.png)



**RocketMQ的零拷贝技术**

一台服务器把本机磁盘文件的内容发送到客户端，分为两个步骤：
1.read：读取本地文件内容 ;
2:write：将读取的内容通过网络发送出去。



这两个看似简单的操作，实际进行了4 次数据复制，分别是：
1.从磁盘复制数据到内核态内存；
2.从内核态内存复 制到用户态内存；
3.然后从用户态 内存复制到网络驱动的内核态内存；
4.最后是从网络驱动的内核态内存复 制到网卡中进行传输



![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210607105400.png)



通过使用mmap（内存共享技术）的方式，可以省去向用户态的内存复制，提高速度。这就是"**零拷贝技术**"



### 3.5 刷盘机制

RocketMQ为了提高性能，会尽可能地保证磁盘的顺序写。消息在通过Producer写入RocketMQ的时 候，有两种写磁盘方式，分布式 **同步刷盘** 和 **异步刷盘**

- 同步刷盘
  在返回写成功状态时，消息已经被写入磁盘。具体流程是，消息写入内存的PAGECACHE后，立刻通知刷盘线程刷盘， 然后等待刷盘完成，刷盘线程执行完成后唤醒等待的线程，返回消息写成功的状态。

- 异步刷盘
  在返回写成功状态时，消息可能只是被写入了内存的PAGECACHE，写操作的返回快，吞吐量大；当内存里的消息量积累到一定程度时，统一触发写磁盘动作，快速写入  

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210607110210.png)



### 3.6 RocketMQ的高可用

RocketMQ分布式集群是通过Master和Slave的配合达到高可用性的。

Master角色的Broker支持读和写，Slave角色的Broker仅支持读。也就是 Producer只能和Master角色的Broker连接写入消息；Consumer可以连接 Master角色的Broker，也可以连接Slave角色的Broker来读取消息。



**消息主从复制**
如果一个Broker组有Master和Slave，消息需要从Master复制到Slave 上，有同步和异步两种复制方式

- 同步复制：同步复制方式是等Master和Slave均写 成功后才反馈给客户端写成功状态；
- 异步复制：异步复制方式是只要Master写成功 即可反馈给客户端写成功状态。





## 4.RabbitMQ

### 4.1 RabbitMQ基础知识

### 4.2 RabbitMQ架构图及其组件

- publisher：向交换机中发送消息

- exchange：交换机。根据路由向队列中发送消息

- queue：队列。接受消息

- consumer：消费消息

  

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210613143304.png)





### 4.3 RabbitMQ交换机类型

#### 4.3.1 直连（Direct）（1个消费者消费一个生产者）

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210405124725.png)注：生产者、队列、消费者



#### 4.3.2 任务模式（work quene）（多个消费者消费一个生产者）（1条消息不能多次消费）

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210405124853.png)

注：生产者、队列、消费者



#### 4.3.3 广播模型（fanout）（交换机将消息推给绑定的队列）（1条消息可以多次消费）

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210405124933.png)

注：生产者、交换机（X）、队列、消费者



#### 4.3.4 路由模型（Routing）

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210421094841.png)



注：生产者、交换机（X）、路由、队列、消费者



#### 4.3.5 订阅模型/主题模式（Topic）

![](https://gitee.com/domineering_red_tide/image/raw/master/image/20210405125041.png)

注：生产者、交换机（X）、路由、队列、消费者

注：* 只匹配一个单词  ； # 匹配一个或多个单词



```
Fanout、Routing、Topic模型区别：
  1.在Fanout模式中，一条消息，会被所有订阅的队列都消费
  2.在Routing模式中，不同的消息被不同的队列消费。推送消息的时候给队列个唯一Routingkey
  3.在Topic模式中，不同的消息被不同的队列消费。推送消息的时候给队列个可匹配多个的Routingkey
```



### 4.4 RabbitMQ如何保证高可用

RabbitMQ有两种集群模式，分别是普通集群和镜像集群，普通模式无法保证RabbitMQ的高可用。

#### 4.4.1 普通集群

假如有三个节点，rabbitmq1、rabbitmq2、rabbitmq3，消息实际上只存在于其中一个节点，三个节点仅有相同的元数据，即队列的结构，当消息进入rabbitmq2节点的queue后，consumer从rabbitmq1的节点进行消费，rabbitmq1和rabbitmq2会进行临时通信，从rabbitmq2中获取消息然后返回给consumer。

这种模式存在以下两个问题：

1. 当rabbitmq2宕机后，消息无法正常消费，没有做到真正的高可用
2. 实际数据还是在单个实例上，存在瓶颈问题

![普通集群](./image/普通集群.png)



#### 4.4.2  镜像集群

假如有三个节点，rabbitmq1、rabbitmq2、rabbitmq3，每个实例之间都可以相互通信，每次生产者写消息到queue的时候，每个rabbitmq节点上都有queue的消息数据和元数据。这种模式适用于可靠性要求较高的场景。

![镜像集群](./image/镜像集群.png)





## 5.MQ的实际使用

### 5.1 如果我有一笔订单，30分钟未支付则关闭订单，使用RabbitMQ如何来实现

RabbitMQ可以使用死信队列来实现延时消费，用户下单之后，将订单信息投递到消息队列中，并且设置消息过期时常为30分钟。如果用户支付则正常关闭订单，如果用户未支付，消息达到过期时间，消息会进入死信交换，由消费者进行消费死信队列来关闭订单。

![死信队列的使用](./image/死信队列的使用.png)

